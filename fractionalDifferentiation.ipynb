{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting specifics and defaults\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['figure.figsize'] = (7, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple integrals\n",
    "\n",
    "Consider the multiple integral\n",
    "\n",
    "$\\int_0^x\\int_0^t\\int_0^sf(x)\\,dx\\,ds\\,dt$\n",
    "\n",
    "not as three integrations, but as one operator that transforms $f(x)$ into some ouput function $g(x)$ that describes its $n^{th}$ order integral. Cauchy wrote this operator as\n",
    "\n",
    "$(I^3f)(x)$ where $I^3$ is the operator representing three integrations. Generalising to $n$ integrations, this can be written as\n",
    "\n",
    "$I^nf(x)=\\dfrac{1}{(n-1)!}\\int_a^x(x-t)^{n-1}f(t)\\,dt$.\n",
    "\n",
    "## Factorial problem\n",
    "\n",
    "However, in trying to generalise this to fractional values, you can't compute $(n-1)!$ unless $n\\in\\mathbb{Z}$ (integers).\n",
    "\n",
    "To get around this, you need to use the gamma function which provides a smooth curve through factorials enabling the generalisation of factorials to non integer values:\n",
    "\n",
    "$\\Gamma(n)=\\int_0^\\infty \\mathrm{e}^{-t}t^{n-1}\\,dt$\n",
    "\n",
    "## Riemann-Liouville fractional integral\n",
    "\n",
    "Now we write $I^nf(x)$ as\n",
    "\n",
    "$I^nf(x)=\\dfrac{1}{\\Gamma(n)}\\int_a^x(x-t)^{n-1}f(t)\\,dt$ for $n\\in\\mathbb{C}$ (with $\\mathbb{R}\\mathrm{e}(n)>0$),\n",
    "\n",
    "which is a Riemann-Liouville fractional integral that can handle noninteger (and complex) values of n as long as the real part is positive.\n",
    "\n",
    "Note that these RL fractional integrals have the following properties:\n",
    "\n",
    "$I^{a+b}f(x) = I^aI^bf(x)$\n",
    "\n",
    "$\\dfrac{d}{dx}I^{a+1}=I^a$\n",
    "\n",
    "## Fractional derivative\n",
    "\n",
    "We want to generalise to\n",
    "\n",
    "$\\dfrac{d^nf}{dx^n}\\quad (n\\in\\mathbb{R})$\n",
    "\n",
    "which can be rewritten using the properties of the RL integral as\n",
    "\n",
    "$\\dfrac{d^nf}{dx^n}(I^nf(x))=f(x)$.\n",
    "\n",
    "Next step toward this is to write the fractional derivative operator as\n",
    "\n",
    "$D^nf=\\dfrac{d^{\\lceil n\\rceil}}{dx^{\\lceil n\\rceil}}\\left( I^{\\lceil n\\rceil -n}f \\right)$\n",
    "\n",
    "where $\\lceil n\\rceil$ is the ceiling of n (round up)\n",
    "\n",
    "## Left Riemann-Liouville fractional derivative\n",
    "\n",
    "Now we can write the fractional derivative using the cauchy formula as\n",
    "\n",
    "$D_a^nf(x)=\\dfrac{1}{\\Gamma(\\lceil n\\rceil -n)}\\dfrac{d}{dx^{\\lceil n\\rceil}}\\int_a^x(x-t)^{\\lceil n\\rceil -n-1}f(t)\\,dt$.\n",
    "\n",
    "Now the fractional derivative is written in terms of regular integral differentiation (because of the ceil operations), and fractional integrations which we managed to make using the gamma function earlier.\n",
    "\n",
    "### Notes\n",
    "\n",
    "Note however, that the fractional derivative doesn't obey things like the chain rule or product rule. Further, the fractional derivative has 'non-locallity' because the outcome depends on more variables than the input (it picks up a dependency on $a$ which was the lower bound of integration)\n",
    "\n",
    "## Stationarity and memory\n",
    "\n",
    "ML algorithms and time series analysis in general require stationarity. This is typically achieved by looking at the daily returns of an asset rather than its absolute value.\n",
    "\n",
    "These returns can be calculated with (integer) differentiation, however, this removes 'memory' of the time series: Some functions have 'memory' which means their current state depend on both time and their previous states. Fractional derivatives make modelling function memory easier apparently.\n",
    "\n",
    "Imagine a series of trending close price data (non stationary as there's a trend so the mean changes with time). Now, look only at the returns. Suddenly, the information about previous values (the memory) has disappeared.\n",
    "\n",
    "One can ask the question: *What is the minimum amount of differentiation that makes a price series stationary while preserving as much memory as possible*?\n",
    "\n",
    "**You're essentially trying to find a compromise between a nonstationary process with memory and a stationary process without memory. The machine learning algorithm wants stationarity, but the desire for informed predictions of future values wants memory**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
